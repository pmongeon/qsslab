---
format: revealjs
editor: visual
---

# Knowing thyself {background-color="white" background-image="images/background_slide.jpg"}

**Bibliometrics as knowledge management tools for research units and communities** <br><br>July 5^th^ 2023 - Guest Lecture<br><br> Philippe Mongeon\
[pmongeon\@dal.ca](pmongeon@dal.ca)\
[www.qsslab.ca](www.qsslab.ca)

## Presentation outline

-   Introduction to bibliometrics
-   From research evaluation
-   ... to knowledge management
-   Challenges and tips and tricks

::: notes
:::

## What are bibliometrics?

-   "The measurement of all aspects related to the publication and reading of books and documents." (Otlet, 1934)

-   "the application of mathematics and statistical methods to books and other media of communication." (Pritchard, 1969)

In principle, bibliometrics could be applied to any type of documents, but in practice they are applied to scholarly outputs to **measure knowledge production, dissemination, and use.**

## What's in a name?

Bibliometrics is a widely used term to refer to the field, but it is not the only (and probably not the best) one. Other (quasi-)synonyms include:

-   Bibliometrics, Scientometrics, info(r)metrics, altmetrics, Quantitative Science Studies

-   Science of science, research on research

Science and technology studies (STS) share the research object but not the methods (STS uses mainly qualitative methods).

## Two underlying assumptions of bibliometrics

-   Peer-reviewed scholarly works are contributions to the advancement of knowledge (or units of knowledge production).

-   Because researchers cite their sources, citations can measure the use (or impact? Quality? Importance?) of a contribution to knowledge.

## Bibliometric data

![Source: https://askabiologist.asu.edu/explore/anatomy-of-an-article](images/article.jpg){fig-align="center" width="800"}

## Entities "knowable" through bibliometrics

-   Works
-   Journals
-   Publishers
-   Authors
-   Research organizations (e.g. Universities
-   Funders
-   Research areas

## Data structure

![](images/openalex-schema.png){fig-align="center"}

## Bibliometric database vs other bibliograhic database

Main advantages of most of the bibliometric databases are:

-   They index more metadata elements from the paper
-   They enrich the metadata by adding elements (e.g., classifications, unique identifiers for authors and other entities)
-   **They index** **citations,** which is why these databases are often called [citation indexes](https://en.wikipedia.org/wiki/Citation_index) (or scientific knowledge graph (SKG), which may be a better name since these databases generally include more than citations).

## Applications of bibliometrics

-   Sociology of science
-   History of science
-   Science policy
-   Library and Information Science
-   Research evaluation
-   Etc.

# Bibliometric data sources

More details on my course website (in development) <https://pmongeon.github.io/bibliometrics-and-scholarly-communication/ch4.html>

## Google Scholar {.smaller}

-   Probably the best coverage
-   Black box
-   Limited access to data

![](images/gs_profile.png)

## Web of Science and InCites {.smaller}

-   Launched by Eugene Garfield and the Institute for Scientific Information in 1963.

-   Main advantages: 1) are its long coverage period, 2) metadata consistency 3) clear inclusion criteria (read about the selection process [here](https://clarivate.com/products/scientific-and-academic-research/research-discovery-and-workflow-solutions/web-of-science/core-collection/editorial-selection-process/)).

-   Web of Science for **information retrieval**, InCites for **research evaluation**.

    ![](images/Web_of_science_next_generation.png){width="800"}

## Scopus, SciVal, and the ICSR lab

-   Launched in 1996 by Elsevier as the first competitor to the Web of Science.

-   Better coverage than Web of Science, but still limited.

-   Scopus for **information retrieval**, SciVal for **evaluation**, and the ICSR lab for **advanced bibliometric research**.

## Dimensions

-   Relatively new database by Digital Science (owned by Springer-Nature).

-   Broader coverage than Web of Science and Scopus.

-   Has a [free online search interface](https://app.dimensions.ai/discover/publication).

-   Can request access to the full database or API for research purposes.

## OpenAlex

-   **Fully open** bibliometric database.
-   Accessible through an API or a database snapshot.
-   Most comprehensive.
-   Metadata quality and completeness sometimes lacking.
-   Still in development.

# Bibliometrics and research evaluation

# Bibliometrics and knowledge management

# The breaking the silos in LIS project

![](images/partners.png){fig-align="center"}

::: notes
First, I want to share with you some details of a project that we undertook, with co-PI Jean-Sébastien Sauvé, assistant professor at the École de bibliothéconomie et des sciences de l'information at the Université de Montréal, and with the support of the organizations listed on the slide. We received a connection grant from SSHRC, with additional funding from CARL, and in-kind contributions from the MISTS, and EBSI.
:::

## Objectives

-   Build an **open and exhaustive database** of the scholarship produced by LIS academics and practitioners in Canada.

-   **Promote the scholarship** produced by LIS academics and practitioners in Canada.

-   **Encourage research collaboration** between academics and practitioners in Canada.

## Researcher-based field delineation

-   Advantages

    -   Less ambiguous than field-delineation based on topics.
    -   Manageable scope.
    -   Capture mutlidisciplinarity within the group/unit.

-   Challenges

    -   Author name disambiguation is tedious.

    -   Mobility

    -   Excludes LIS scholars with non-LIS affiliations and non-LIS scholars contributing to the LIS scholarship.

## Data sources/process

-   Canadian Academic Libraries and LIS department websites.

-   Google Scholar and ORCID.

-   OpenAlex

# Outcomes

## A dataset of LIS practitioners and academics

-   About 2,630 individuals (2022 librarians, 608 academics) from 93 institutions.

-   6500+ publications (journal articles, books, book chapters, conference proceedings).

-   OpenAlex author IDs and work IDs, Google Scholar IDs, ORCIDs, etc.

-   Citation index (including links to records outside of the dataset)

-   Web app to explore and visualize the data.

## Map of research by LIS academics

![](images/cc_dc_nodes_labels_v3.png)

## Topic specialization (publications)

![](images/specialization%20index%20(publications).png){fig-align="center"}

## Topic specialization (authors)

![](images/specialization%20index%20(authors).png){fig-align="center"}

## Collaboration between academics and practitioners (ongoing)

**Two objectives**

1.  To map the scholarship produced by Canadian LIS scholars and academic librarians to identify similarities and differences in research output, impact, topics, and publication venues.
2.  To measure the degree of engagement between scholars and practitioners through research collaborations or references to the scholarship produced by each group.

## Next steps

-   Data cleaning.

-   Publication of full dataset.

-   Publication of the Shiny app.

-   Publication of scripts to optimize the data collection/cleaning process.

# Embracing the silos

## Towards an open national bibliometric data infrastructure

-   Institutional data stewardship

    -   Systematic collection of research output published by the institution.

        -   Only the metadata!

    -   Mobilizing institutional repositories for full text when possible.

    -   Disambiguation of authors affiliated with the institution.

## An opportunity for libraries

-   Core skills of LIS practitioners.
-   Emerging mandate in academic libraries.
-   Core values of LIS practitioners.
-   Vroom's expectancy theory: Motivational Force (MF) = Expectancy x Instrumentality x Valence
    -   **Expectancy**: Belief that the outcome will be achieved.

    -   **Instrumentality**: Belief that a reward will be obtained.

    -   **Valence**: The value placed on the reward/outcome.

## Keeping it small and simple

-   The number of individuals included in the breaking the silos project is about three times the size of Dalhousie University.

-   Local data for local needs

-   No more data than is needed.

## The right tool for the job

-   Bibliometrics do not need to be about impact.

-   Technologies can be overrated.

-   Beware of tools that just create more work.

-   Manage your urge to automate processes.

## A wish list

-   Open disambiguated publication data for all Canadian universities.
-   Open and exhaustive classification(s) of journals.
-   Normalization denominators.

# Building collective capacity, one silo at a time.

# Thank you!

Philippe Mongeon, Dalhousie University - [pmongeon\@dal.ca](pmongeon@dal.ca) - [www.qsslab.ca](www.qsslab.ca)

![](images/partners.png){fig-align="center"}
